{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea0d2efa5d48efb5d113e68a51228c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f0a552f53b480eb78362cbed01548a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9fdc9cb6954f16b6a08752515aec81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0506e04ce9e64cea83f3baacf2bec8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/34/89/348935208b8079693ff4d1c9dcaaccb94051016ef4bb7ac3bdc16565432c772a/2c63ead1f2c68d6511ff3154d5549f811b0e71682fe0bc10899db5d1b32afcab?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00005.safetensors%3B+filename%3D%22model-00001-of-00005.safetensors%22%3B&Expires=1720495485&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDQ5NTQ4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzM0Lzg5LzM0ODkzNTIwOGI4MDc5NjkzZmY0ZDFjOWRjYWFjY2I5NDA1MTAxNmVmNGJiN2FjM2JkYzE2NTY1NDMyYzc3MmEvMmM2M2VhZDFmMmM2OGQ2NTExZmYzMTU0ZDU1NDlmODExYjBlNzE2ODJmZTBiYzEwODk5ZGI1ZDFiMzJhZmNhYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=GeF4QAlOzCo0KgCSjeWP4hrCO67GJZoWhyGT74dhMvxXLibIUqPvLor21kmX%7EBtJKMbFhJl1bYI20tfs5Oc-B7BMwrg0YaYrWDiPAsuSpGCcH1vLQPqMsv5CTc3sSZk0TFbna21U33Bg7Uym1OpY4iMV2ZacdVruwuREaN3hpRbCun2wZfEQw5CFUQSicrHDEFiZoSkqWyG5nptCwJAhPWI8ARYx6fgVEJZ-z1271PMtNhpqNOQrWc1B7xETubRkqeJhmrY-CBmSVD9Ab%7EVMitWjLV%7Em7vKEKwh36E6L10xl0AnQ0FjYX6W0TQ453Crzy0wUAwOfRjk-tep%7EWAtfWg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a67c7e0aafb48e4b331354ca9a86387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:  58%|#####7    | 2.86G/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/34/89/348935208b8079693ff4d1c9dcaaccb94051016ef4bb7ac3bdc16565432c772a/2c63ead1f2c68d6511ff3154d5549f811b0e71682fe0bc10899db5d1b32afcab?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00005.safetensors%3B+filename%3D%22model-00001-of-00005.safetensors%22%3B&Expires=1720495485&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDQ5NTQ4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzM0Lzg5LzM0ODkzNTIwOGI4MDc5NjkzZmY0ZDFjOWRjYWFjY2I5NDA1MTAxNmVmNGJiN2FjM2JkYzE2NTY1NDMyYzc3MmEvMmM2M2VhZDFmMmM2OGQ2NTExZmYzMTU0ZDU1NDlmODExYjBlNzE2ODJmZTBiYzEwODk5ZGI1ZDFiMzJhZmNhYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=GeF4QAlOzCo0KgCSjeWP4hrCO67GJZoWhyGT74dhMvxXLibIUqPvLor21kmX%7EBtJKMbFhJl1bYI20tfs5Oc-B7BMwrg0YaYrWDiPAsuSpGCcH1vLQPqMsv5CTc3sSZk0TFbna21U33Bg7Uym1OpY4iMV2ZacdVruwuREaN3hpRbCun2wZfEQw5CFUQSicrHDEFiZoSkqWyG5nptCwJAhPWI8ARYx6fgVEJZ-z1271PMtNhpqNOQrWc1B7xETubRkqeJhmrY-CBmSVD9Ab%7EVMitWjLV%7Em7vKEKwh36E6L10xl0AnQ0FjYX6W0TQ453Crzy0wUAwOfRjk-tep%7EWAtfWg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5638a6085c84a46bdec2c04d6e6c132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:  72%|#######1  | 3.54G/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"upstage/SOLAR-10.7B-Instruct-v1.0\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def precision_recall_f1(true_tokens, pred_tokens):\n",
    "    true_set = set(true_tokens)\n",
    "    pred_set = set(pred_tokens)\n",
    "    \n",
    "    tp = len(true_set & pred_set)\n",
    "    fp = len(pred_set - true_set)\n",
    "    fn = len(true_set - pred_set)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision,recall, f1\n",
    "def text_similarity_f1(text1, text2):\n",
    "    tokens1 = tokenize(text1)\n",
    "    tokens2 = tokenize(text2)\n",
    "    \n",
    "    precision, recall, f1 = precision_recall_f1(tokens1, tokens2)\n",
    "    \n",
    "    return precision,recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# load json\n",
    "# /data/taeho/self-rag/email_data.json\n",
    "with open(\"./data/taeho/self-rag/email_data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "# to string\n",
    "docs = [d[\"text_body\"][0] for d in data if len(d[\"text_body\"]) > 0]\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide most correct answer from the following context. \n",
    "    If the answer is not present in the context, please write \"The information is not present in the context.\"\n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {Context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Upstage/SOLAR-10.7B-Instruct-v1.0\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "for i in range(len(docs)):\n",
    "    a = tokenizer.encode(docs[i], return_tensors=\"pt\", max_length=4000, truncation=True)\n",
    "    docs[i]= tokenizer.decode(a[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "sample_docs = [Document(page_content=text) for text in docs]\n",
    "\n",
    "\n",
    "# if ./chroma_db not exist\n",
    "if not os.path.exists(\"./data/taeho/chroma_db\"):\n",
    "    vectorstore = Chroma.from_documents(\n",
    "            documents=sample_docs,\n",
    "            embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "            ,persist_directory=\"./data/taeho/chroma_db\",\n",
    "    )\n",
    "else:\n",
    "    vectorstore = Chroma(persist_directory=\"./data/taeho/chroma_db\",\n",
    "                embedding_function=UpstageEmbeddings(model=\"solar-embedding-1-large\", ))\n",
    "    \n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "while True:\n",
    "    query = input(\"질문을 입력해주세요: \")\n",
    "    docs = retriever.invoke(query)\n",
    "    for _ in range(5):\n",
    "        answer = chain.invoke({\"question\": query, \"Context\": docs})\n",
    "        gc_result = groundedness_check.invoke({\"context\": docs, \"answer\": answer})\n",
    "        print(\"GC check result: \", gc_result)\n",
    "        if gc_result.lower().startswith(\"grounded\"):\n",
    "            print(\"✅ Groundedness check passed\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Groundedness check failed\")\n",
    "            continue\n",
    "    print(\"Answer: \", answer)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit ('3.11.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efd79ad9cdf10d9e570318ced942ec0471144321c1dcf70a46eeb648dbab3cca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
